{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "import json\n",
        "\n",
        "class AILinkedInRecruitmentTool:\n",
        "    def __init__(self, job_requirements: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize the recruitment AI tool with job requirements\n",
        "\n",
        "        :param job_requirements: Dictionary containing job specification details\n",
        "        \"\"\"\n",
        "        self.job_requirements = job_requirements\n",
        "\n",
        "        # Load spaCy for advanced NLP processing\n",
        "        try:\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "        except OSError:\n",
        "            print(\"Downloading spaCy language model...\")\n",
        "            os.system('python -m spacy download en_core_web_sm')\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "        # Candidates database (simulated - would be replaced with actual LinkedIn data)\n",
        "        self.candidates_db = []\n",
        "\n",
        "    def preprocess_linkedin_profile(self, profile: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Preprocess and clean LinkedIn profile data\n",
        "\n",
        "        :param profile: Raw LinkedIn profile dictionary\n",
        "        :return: Cleaned and structured profile\n",
        "        \"\"\"\n",
        "        processed_profile = {\n",
        "            'name': profile.get('name', ''),\n",
        "            'headline': profile.get('headline', ''),\n",
        "            'experience': self._extract_experience(profile.get('experience', [])),\n",
        "            'skills': self._extract_skills(profile.get('skills', [])),\n",
        "            'education': self._extract_education(profile.get('education', [])),\n",
        "            'summary': profile.get('summary', '')\n",
        "        }\n",
        "        return processed_profile\n",
        "\n",
        "    def _extract_experience(self, experiences: List[Dict]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Extract and process work experience\n",
        "\n",
        "        :param experiences: List of experience dictionaries\n",
        "        :return: List of processed experience descriptions\n",
        "        \"\"\"\n",
        "        processed_experiences = []\n",
        "        for exp in experiences:\n",
        "            desc = f\"{exp.get('title', '')} at {exp.get('company', '')} - {exp.get('description', '')}\"\n",
        "            processed_experiences.append(desc)\n",
        "        return processed_experiences\n",
        "\n",
        "    def _extract_skills(self, skills: List[Dict]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Extract skills from profile\n",
        "\n",
        "        :param skills: List of skill dictionaries\n",
        "        :return: List of skill names\n",
        "        \"\"\"\n",
        "        return [skill.get('name', '').lower() for skill in skills if skill.get('name')]\n",
        "\n",
        "    def _extract_education(self, education: List[Dict]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Extract education details\n",
        "\n",
        "        :param education: List of education dictionaries\n",
        "        :return: List of education descriptions\n",
        "        \"\"\"\n",
        "        return [f\"{edu.get('degree', '')} from {edu.get('school', '')}\" for edu in education]\n",
        "\n",
        "    def calculate_skill_match(self, candidate_skills: List[Dict], required_skills: List[str]) -> float:\n",
        "        \"\"\"\n",
        "        Calculate skill match percentage\n",
        "\n",
        "        :param candidate_skills: List of candidate skills\n",
        "        :param required_skills: List of required job skills\n",
        "        :return: Skill match percentage\n",
        "        \"\"\"\n",
        "        candidate_skill_names = [skill.get('name', '').lower() for skill in candidate_skills if skill.get('name')]\n",
        "        candidate_skills_set = set(candidate_skill_names)\n",
        "        required_skills_set = set(required_skills)\n",
        "\n",
        "        matching_skills = candidate_skills_set.intersection(required_skills_set)\n",
        "        match_percentage = (len(matching_skills) / len(required_skills_set)) * 100 if required_skills_set else 0\n",
        "\n",
        "        return match_percentage\n",
        "\n",
        "    def semantic_similarity(self, text1: str, text2: str) -> float:\n",
        "        \"\"\"\n",
        "        Calculate semantic similarity between two texts using spaCy\n",
        "\n",
        "        :param text1: First text\n",
        "        :param text2: Second text\n",
        "        :return: Semantic similarity score\n",
        "        \"\"\"\n",
        "        doc1 = self.nlp(text1)\n",
        "        doc2 = self.nlp(text2)\n",
        "        return doc1.similarity(doc2)\n",
        "\n",
        "    def ai_candidate_ranking(self, candidates: List[Dict], job_description: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Rank candidates using AI techniques\n",
        "\n",
        "        :param candidates: List of candidate profiles\n",
        "        :param job_description: Job description text\n",
        "        :return: Ranked list of candidates\n",
        "        \"\"\"\n",
        "        ranked_candidates = []\n",
        "\n",
        "        for candidate in candidates:\n",
        "            # Skill match calculation\n",
        "            skill_match_score = self.calculate_skill_match(\n",
        "                candidate.get('skills', []),\n",
        "                self.job_requirements.get('required_skills', [])\n",
        "            )\n",
        "\n",
        "            # Semantic similarity of profile to job description\n",
        "            # The experience key contains a list of dictionaries,\n",
        "            # so we need to extract the descriptions first\n",
        "            experiences = candidate.get('experience', [])\n",
        "            experience_descriptions = [exp for exp in experiences] # Extract the descriptions into a list\n",
        "\n",
        "            # Now join the descriptions\n",
        "            semantic_match_score = self.semantic_similarity(\n",
        "                ' '.join(map(str, experience_descriptions)) + candidate.get('summary', ''), # Convert to string using map(str, )\n",
        "                job_description\n",
        "            )\n",
        "\n",
        "            # Combined scoring mechanism\n",
        "            total_score = (skill_match_score * 0.6) + (semantic_match_score * 40)\n",
        "\n",
        "            candidate_result = {\n",
        "                'name': candidate.get('name'),\n",
        "                'skill_match': skill_match_score,\n",
        "                'semantic_match': semantic_match_score,\n",
        "                'total_score': total_score\n",
        "            }\n",
        "\n",
        "            ranked_candidates.append(candidate_result)\n",
        "\n",
        "        # Sort candidates by total score in descending order\n",
        "        ranked_candidates.sort(key=lambda x: x['total_score'], reverse=True)\n",
        "\n",
        "        return ranked_candidates\n",
        "\n",
        "    def generate_candidate_report(self, top_candidates: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        Generate a detailed report of top candidates\n",
        "\n",
        "        :param top_candidates: List of top-ranked candidates\n",
        "        :return: Formatted report string\n",
        "        \"\"\"\n",
        "        report = \"AI Recruitment Candidate Report\\n\"\n",
        "        report += \"=\" * 50 + \"\\n\\n\"\n",
        "\n",
        "        for i, candidate in enumerate(top_candidates[:5], 1):\n",
        "        # Indented block for the loop\n",
        "            report += f\"Candidate {i}:\\n\"\n",
        "            report += f\"Name: {candidate['name']}\\n\"\n",
        "            report += f\"Skill Match: {candidate['skill_match']:.2f}%\\n\" # Corrected line\n",
        "            report += f\"Semantic Match: {candidate['semantic_match']:.2f}\\n\"\n",
        "            report += f\"Total Score: {candidate['total_score']:.2f}\\n\\n\"\n",
        "\n",
        "        return report"
      ],
      "metadata": {
        "id": "ZBJhyzcATrf2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example job requirements\n",
        "job_requirements = {\n",
        "    'required_skills': ['python', 'machine learning', 'data analysis'],\n",
        "    'job_description': \"We are looking for a skilled Python developer with experience in Machine Learning and Data Analysis.\"\n",
        "}\n",
        "\n",
        "# Example candidate profile data\n",
        "candidates = [\n",
        "    {\n",
        "        'name': 'John Doe',\n",
        "        'headline': 'Data Scientist at XYZ Corp',\n",
        "        'experience': [\n",
        "            {'title': 'Data Scientist', 'company': 'XYZ Corp', 'description': 'Worked on machine learning algorithms'}\n",
        "        ],\n",
        "        'skills': [{'name': 'python'}, {'name': 'machine learning'}, {'name': 'data analysis'}],\n",
        "        'education': [{'degree': 'Master\\'s', 'school': 'University of ABC'}],\n",
        "        'summary': \"Experienced data scientist with a background in machine learning and data analysis.\"\n",
        "    },\n",
        "    {\n",
        "        'name': 'Jane Smith',\n",
        "        'headline': 'Software Engineer at ABC Tech',\n",
        "        'experience': [\n",
        "            {'title': 'Software Engineer', 'company': 'ABC Tech', 'description': 'Worked on Python-based applications'}\n",
        "        ],\n",
        "        'skills': [{'name': 'python'}, {'name': 'software development'}],\n",
        "        'education': [{'degree': 'Bachelor\\'s', 'school': 'University of XYZ'}],\n",
        "        'summary': \"Software engineer specializing in Python programming.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize the tool\n",
        "tool = AILinkedInRecruitmentTool(job_requirements)\n",
        "\n",
        "# Rank candidates\n",
        "ranked_candidates = tool.ai_candidate_ranking(candidates, job_requirements['job_description'])\n",
        "\n",
        "# Generate the report\n",
        "report = tool.generate_candidate_report(ranked_candidates)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hefE2vHVr2c",
        "outputId": "09093dee-d990-4a6d-edf5-5d5eb18f77a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Recruitment Candidate Report\n",
            "==================================================\n",
            "\n",
            "Candidate 1:\n",
            "Name: John Doe\n",
            "Skill Match: 100.00%\n",
            "Semantic Match: 0.39\n",
            "Total Score: 75.58\n",
            "\n",
            "Candidate 2:\n",
            "Name: Jane Smith\n",
            "Skill Match: 33.33%\n",
            "Semantic Match: 0.34\n",
            "Total Score: 33.65\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-eb271eda849e>:106: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  return doc1.similarity(doc2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oa_lXh9lWF2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}